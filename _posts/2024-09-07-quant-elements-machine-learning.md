---
layout: single
title:  "퀀트의 필수 요소 (7/7): 머신러닝"
description: 퀀트 투자에 필요한 요소인 머신러닝 대하여 정리하였다.
categories: 투자
tag: [주식,책,퀀트]
toc: true
author_profile: false
header:
 teaser: /images/2024-09-07-quant-elements-machine-learning/quant-elements-machine-learning-thumbnail.webp
 og_image: /images/2024-09-07-quant-elements-machine-learning/quant-elements-machine-learning-thumbnail.webp

# sidebar:
#     nav: "docs"
# search: true
---
퀀트의 기반이 되는 데이터 분석에 머신러닝을 사용할 수 있다.

{: .notice--primary}
<span style="font-size: 1.25em;">이 글은 [퀀트의 정석] 책에 나오는 머신러닝 부분을 정리한 것이다.</span>

[퀀트의 정석](/투자/quant-way-book/)

# 빅데이터와 대체데이터

## 빅데이터
빅데이터는 대량의 데이터가 체계적인 집합을 이루고 있는 것을 의미한다. 어떤 데이터의 집합이 양, 속도, 그리고 다양성 측면에서 매우 클 때, 우리는 이러한 데이터 집합을 빅데이터라고 부를 수 있다.

- 양(Volume): 빅데이터는 수집되어 저장된 데이터의 사이즈가 매우 크다. 따라서 인간의 눈으로는 쉽게 인지하거나 분석할 수 없으며, 엑셀로도 처리하기 어렵다.

- 속도(Velocity): 빅데이터는 송수신하는 속도 또한 매우 빠르다. 일반저그로 스트리밍 방식이나 배치 방식을 통해 전송되는데, 이러한 전송은 거의 실시간으로 발생한다.

- 다양성(Variety): 빅데이터는 데이터의 형태가 매우 다양하다. SQL이나 CSV 같은 기존의 정형화 된 데이터를 포함하여, JSON이나 HTML 같은 반정형화 데이터, 그리고 댓글이나 블로그 포스트, 트위터, 이미지, 영상 같은 매우 비정형화된 데이터를 모두 포함한ㄷ.

## 대체데이터
대체 데이터는 기존의 일반적인 형태의 데이터가 아닌 새로운 종류와 형태의 데이터를 모두 포함하는 용어다. 대체 데이터는 생성된 소스에 따라 개인 데이터, 비즈니스 데이터, 그리고 센서 데이터로 구분한다. 이러한 분류 방식은 각각의 카테고리 내의 데이터들이 해당 카테고리가 공유하는 공통적인 성질, 분석방법론, 그리고 장단점들을 함께 공유하고 있기 때문이다.

예를들어, 개인에 의해 생성된 데이터는 일반적으로 비정형화된 텍스트의 형태이며, 따라서 이러한 데이터를 처리하기 위해서는 자연어 처리 기술이 요구된다. 또한 신용카드 거래내역과 같이 비즈니스를 통해 만들어진 데이터는 접근하고 사용하기 위한 법적인 이슈 그리고 개인정보 보호와 같은 프라이버시 이슈등에 대한 고려가 필요하다. 마지막으로 각종 센서에 의해 생성된 데이터는 물체의 개수를 세거나 인공위성에 잡힌 구름, 날씨 변화의 효과를 제거해 주는 것과 같은 특수한 데이터 처리기술이 필요하다.

### 개인데이터
개인 데이터는 텍스트 형태를 갖고 있기 때문에 비정형화 되어 있으며 다양한 플랫폼으로부터 생산된다. 플랫폼은 트위터, 페이스북, 링크드인과 같은 SNS, 각종 상품 리뷰 웹사이트, 그리고 구글, 네이버 같은 웹사이트에서의 검색기록으로 나눌 수 있다. 이러한 데이터는 자연어 처리를 통해 분석하여 현재 수많은 사람의 생각과 감정이 어떠한지 알 수 있다. RavenPack과 같은 회사는 이러한 자연어 처리 기술을 기반으로 금융투자회사에 리서치 및 데이터 서비스를 제공하는 대표적인 예시다.


### 비즈니스 데이터
비즈니스 데이터는 회사 혹은 공공기관로부터 만들어지고 수집된 데이터를 의미한다. 여기에는 신용카드 사용 기록, 은행 이체 기록, 슈퍼마켓 바코드 기록, 공급망 데이터 등이 포함된다. 비즈니스 데이터는 고도로 정형화되어있는 것이 많다. 또한 이러한 데이터는 기업실적, 재무제표 데이터 등의 선행지표 역할을 하고 있다. 공공기관으로 부터 만들어지는 데이터 또한 비즈니스 데이터로 분류가 되는데, 최근 API를 통해 수집이 가능한 정부 부처 및 공공기관 데이터들이 여기에 해당한다.

### 센서 데이터
센서 데이터는 컴퓨터, 냉장고, 세탁기, CCTV 등과 같이 각종 IoT 기기에 부착된 센서를 통해 수집되는 데이터를 의미한다. 보통 센서에 의한 데이터는 비정형화되어 있으며 다른 데이터보다 상대적으로 그 양이 엄청나게 많다. 이러한 센서 데이터의 대표적인 예시는 인공 위성 이미지다. 인공위성 이미지는 건설, 운반, 제조, 농업 등 다양한 경제할동 들을 실시간으로 모니터링하는 데 사용이 가능하다.

# 머신러닝

## 머신러닝의 분류

### 지도학습
지도 학습에서는 알고리즘에게 입력 데이터와 출력 데이터가 주어지며, 이를 통해 표본 외 데이터, 즉 미래 데이터에 대한 가장 좋은 예측력을 가지는 모델을 찾는다. 지도학습은 좀 더 세부적으로 회귀와 분류로 나누어질 수 있다. 

회귀는 어떤 입력변수가 주어졌을 때 이를 기반으로 연속적인 값을 갖는 출력변수를 예측하는 모델이다. 이의 예시로는 갑작스러운 인플레이션이 발생했을 때 시장은 어떻게 반응할 것인가가 있다. 분류는 출력값을 특정 카테고리로 분류하는 모델이다. 예를 들어, 물가, GDP, 주가등의 입력변수가 주어졌을 때 달러를 살 것인가 말 것인가 하는 이진적인 의사결정 같은 것이 분류모델이 풀어야할 문제다.

흔히 알고있는 선형회귀 모델 또한 이러한 지도학습의 일종이다. 그러나 선형회귀 모델은 너무나 단ㅅ누해서 변수들 간의 실제 상관관계를 알아내는데는 한계가 있다. 예를들어, 인플레이션은 주식시장에 호재로 작용하나, 너무 강한 인플레이션은 오히려 주가에 악영향을 끼치는데 선형회귀 모델은 이렇한 변수들간의 비선형적 관계를 설명할 수가 없다.

회귀모델에는 여러가지 세부적인 방법론이 있다. 먼저, 가장 간단한 형태의 회구 모델은 라쏘 회귀다. 이 방법은 가장 설명력이 높은 입력변수들을 최소한으로 선택하여 상관관계를 찾아내려 한다. 또한 K-최근접 이웃 알고리즘은 과거 데이터를 보고 비슷한 상황들이 발생한다면 어떤 결과가 나올 것인지 예측하는 모델이다. 

분류모델의 대표적인 예는 로지스틱 회귀가 있다. 이는 수많은 입력변수들이 있을 때 이를 기반으로 주식을 살 것인가 말 것인가 같은 이진 의사결정을 할 때 주로 사용된다. 의사결정 트리 또한 분류모델의 일종이며, 이것은 연속적인 의사결정 과정에 기반하여 결과를 예측하기 위한 최적의 법칙을 찾으려 하는 방식이다. 의사결정 트리는 과거 수익률을 매우 잘 설명해주지만 표본외 성과가 그리 좋지 못하다는 단점이 있다. 랜덤 포레스트는 의사결정 트리의 단점을 보완한 방법인데, 수많은 의사결정 트리를 무작위로 생성해 놓고 그것들의 결과를 취합하여 결과를 도출한다.

### 비지도학습
비지도 학습은 데이터들의 공통적인 특징을 찾아 데이터들의 구조를 파악하기 위한 방법론이다. 비지도학슴 모델은 아무런 레이블이 달리지 않는 데이터를 받게된다. 여기서 알고리즘은 데이터들 간의 공통점을 찾고, 그룹 지어진 데이터들을 공통적으로 설명하는 요인이 무엇인지 찾으려 학습한다. 비지도학습은 군집화와 차원축소로 나뉘어진다. 

군집화는 데이터들의 닮은 꼴에 기반하여 전체 데이터를 몇개의 그룹으로 나누낟. 이 방법을 활용한 예는, 고변동성/저변동성 국면, 금리 상승/하락 국면, 물가 상승/하락 국면을 나누는 알고리즘이 있다. 만약 이러한 국면에 대한 구분이 된다면, 각각에 대해 적절한 포트폴리오 비중을 조절함으로써 투자의 성과를 높일 수 있다. 군집화의 가장 대표적인 알고리즘은 K-평균 알고리즘인데, 이 알고리즘은 분산을 최소화하는 K개의 그룹을 만드는 방식이다.

차원축소는 데이터 이면의 주요한 요소를 파악하기 위한 비지도학습 방법이다. 빅데이터라는 고차원 공간에는 실제 시장을 움직인은 주요한 변수들이 어떤 것인지 파악하기 쉽지 않다. 차원축소는 이러한 고차원 데이터를 저차원에 투영하여 정보를 조금 더 효율적으로 나타내기 위한 분석 방법이다. 주성분 분석, 독립성분 분석, 그리고 t-SNE 같은 방법들이 대표적인 예시들이다.

### 강화학습
강화학습은 알고리즘이 최종 보상 수준을 극대화할 수 있는 행동을 스스로 선택하게 하는 방법이다. 예를들면, 강화학습 모델은 100번의 매매 후 최종 손익을 극대화 할 수 있는 트레이딩 법칙을 찾는 것과 같은 문제들을 풀기위해 존재한다. 에이전트라고 불리는 강화학습 알고리즘은 주어진 환경을 관찰하고 행동함으로써 그 환경으로 부터 긍정적 또는 부정적 보상을 받게된다. 이러한 보상을 기반으로 자신의 행동이 좋은 것이었는지 아닌지를 판단한 후 다음 행동을 결정한다. 에이전트는 이러한 시행착오를 반복하면서 보상을 극대화하기 위한 학습을 하게 된다.

## 트레이드 오프
다양한 상황, 다양한 데이터셋 하에서 최고의 성능을 낼 수 있는 단 하나의 절대적인 머신러닝 알고리즘은 존재하지 않는다. 즉, 어떤 데이터로 굉장히 좋은 성과를 내는 모델이 다른 데이터로는 좋지 못한 성과를 낼 수도 있으며, 과거 데이터로 수익을 냈던 백테스팅 결과가 실제로는 손실을 볼수도 있는 것이다. 표본 외 데이터에 대한 예측 안정성을 유지하는 것은 퀀트 트레이딩 영역에서 가장 달성하기 어려운 일 중 하나인데, 빅데이터와 머신러닝을 활용한 전략들 또한 이러한 상황에서 예외가 될 수 없다.

이러한 이슈에서 가장 핵심이 되는 이론은 바로 편향과 분산간의 트레이드오프 관계(Bias-Variance Tradeoff)다. 이는 표본 외 예측이라는 것이 세가지 이유에 의해 나빠질 수 있다는 것을 의미한다. 세가지 이유는 표본 내 에러, 모델의 불안정성, 그리고 랜덤에러이며, 예측에 대한 오류는 이 세가지의 합으로 표현될 수 있다.

모델 예측력의 질을 결정하는 두가지 요인은 표본 내 에러와 모델의 불안정성이다. 표본 내 에러는 모델 자체가 과거 데이터를 제대로 설명하지 못하는 데에서 발생하는 오류다. 표본 내 에러가 크다는 거슨 향후 미래 데이터를 예측함에 있어서도 모델의 성과가 좋지 못할 가능성이 크다는 것을 의미한다. 이는 모델 편향이라고 불리는데, 모델에 새로운 파라미터를 추가하여 복잡도를 증가시키면 모델 편향을 감소시킬 수 있다. 하지만 보통 이러한 과정은 과최적화로 이어지며, 표본 외 에러를 증가시키고 예측력을 떨어트린다. 모델의 복잡도가 증가하면 모델의 불안정성이 높아지기 때문이다. 우리는 이것을 모델 분산이라고 부른다. 

결국 머신러닝의 핵심은 모델 편향과 모델 분산간의 최적 점을 찾는 것이라고 볼 수 있다. 모델 예측력의 질은 모델 복잡도에 대한 함수다. 모델의 복잡도가 증가하면 할수록 표본 내 에러는 줄어들지만, 반대로 모델의 불안정성이 커지게된다. 

# 머신러닝의 퀀트 적용

## 주성분 분석을 활용한 통계적 팩터
머신러닝이 퀀트 투자에 활용될 수 있는 첫번째 예시는 주성분 분서글 통해 데이터 기반의 통계적 팩터를 만들어내는 것이다.
차원 축소를 활용하면 고차원의 데이터셋으로부터 우리가 식별 가능한 몇가지 주요한 성분을 추출해 낼 수 있다. PCA(Principal Component Analysis)라는 주성분 분석 기법을 사용하면 이러한 차원축소가 가능하다.

주성분 분석은 데이터의 분산, 즉 데이터의 변동을 가장 잘 설명할 수 있는 특성을 찾는 비지도 학습 기법이다. 이렇게 나온 주요한 성분들을 주성부이라고 부르는데, 이러한 주성분들은 데이터의 움직임을 설명할 수 있는 요소들이다. 이를 활용하면 연역적으로 생각하지 못했던 새로운 팩터들을 발견할 수 있다. 

이렇게 추출한 팩터들은 순수한 데이터 기반 팩터이기 때문에 귀납적 팩터이자 통계적 팩터가 된다. 이러한 통계적 팩터는 그것이 경제적으로 어떤 의미를 가지고 있는지 해석할 수 없다는 한계가 있다. 이러한 모델의 해석성, 즉 설명가능성이라는 것은 대부분의 머신러닝 모델들이 가지고 있는 문제이기 우리는 이를 활용할 때 이러한 한계점을 인지할 필요가 있다. 실패하는 머신러닝 펀드의 대표적인 원인은 이러한 모델의 한계를 간과하고 이를 사용했기 때문인 경우가 있다.

## 계층적 리스크 패러티
계층적 리스크 패리티는 자산배분에서 기존 MVO 모델이 가지고 있는 한계점을 해결하고자 나온 클러스터링 기반의 자산배분 모델이다. MVO 모델의 문제는 자산들 간의 상간관계가 높을 경우 가중치를 산출하는 데 있어 안정성이 떨어진다는 것이다. 이러한 문제는 마코위츠의 저주라고도 불리는데, 전통적으로 자산배분을 하는 투자 매니저들에게 골칫거리였다.

이러한 문제를 해결하기 위해 계층적 리스크 패리티는 투자 유니버스에 포함되어 있는 자산 혹은 팩터들 간의 상관성을 측정하여 비슷한 성질의 것끼리 군집화를 시킨다. 이러한 군집화는 비지도 학습 기반의 클러스터링 기법을 사용하여 이루어진다.

계층적 리스크 패리티의 기본 논리는 상관성이 높은, 즉 서로 특징이 비슷한 녀석들끼리 클러스터를 만든 뒤 개별 자산이나 팩터가 아닌 클러스터에 위험 예산을 배분하자는 것이다. 이렇게 하면 서로 성격이 다른 클러스터들에 자산배분이 이루어지게 되며 이는 포트폴리오의 안정성과 견고함을 보다 높일 수 있게 된다.